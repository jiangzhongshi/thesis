\section{Related Work}
\label{wmtk:sec:related}

\subsection{Mesh Data Structures}

Efficient data structures for representing solid geometry have been an intriguing
research topic since the early days of computer graphics \cite{Requicha1980}. As
a result, there is a large variety of mesh data structure designs, where they
are each optimized for different usage scenarios. Index-array-based mesh data
structure encodes each element as a list of vertex indices on its
boundary.  It is simple and memory efficient, but neighborhood query and local
operations are not directly supported.
Graph-based mesh data structures, including half-edge \cite{Maentylae1987},
winged-edge \cite{Baumgart1972}, quad-edge \cite{Guibas1985}, cell-tuple
\cite{Brisson1989}, etc., view meshes as graphs, where each element contains
links to its adjacent elements. This design allows for efficient local query
and update, making it ideal for algorithms like mesh simplification
\cite{garland1997surface}. Linear-algebra-based mesh data structures, such as
\cite{Dicarlo2014,Zayer2017,Mahmoud2021}, encode adjacency information as sparse
matrices.  This design elegantly reduces neighborhood query and local operations
to sparse matrix computations, which are highly optimized for modern parallel
computing architecture. \revision{Closely related, is the concept of generalized combinatorial maps \cite{lienhardt1994n, dufourd1991obj3}, and the CGoGN library \cite{kraemer2014cgogn} provide an efficient implementation which provide parallel traversal of the mesh.}
%
By design, mesh data structures provide a low-level interface to
manipulate vertices, edges, faces, and tetrahedra.
Different designs differ vastly in API and implementation details, making it hard to port algorithm from one data structure to another. In contrast, our framework decouples mesh data structure choice from algorithm specification, providing the flexibility of switching the underlying data structure in a seamless manner.







%% Classic mesh data structure.
%Efficient data structure for representing solid geometry as piecewise linear
%cell complex has been an intriguing research topic since the early days of
%computer graphics \cite{Requicha1980}. The widely used half-edge data structure
%\cite{Maentylae1987} and its close siblings, winged-edge \cite{Baumgart1972} and
%quad-edge \cite{Guibas1985}, took an edge-centric view of 2-manifold surfaces,
%where each edge is represented as 2 oppositely oriented half-edges with links to
%their incident vertices and face.  The half-edge data structure is commonly used
%in geometry processing library
%(such as \cite{cgal2008computational,botsch2002openmesh})
%for its constant-time local adjacency queries and
%efficient local operations like edge collapse and split.
%Recent half-edge-inspired data structures such OpenVolumeMesh
%\cite{kremer2013openvolumemesh} 
%and
%Array-Based Half-Facet \cite{Dyedov2015} removes the limitation of 2-manifold
%surface and are capable of representing non-manifold and 3D cell
%complexes.
%The Cell-tuple structure \cite{Brisson1989} generalizes half-edge to provide a
%unified representation of subdivided manifolds of arbitrary dimension.
%\QZ{Mabye add a brief statement on why we pick cell-tuple  over others.}
%
%% Linear-algebra-based data structure.
%With the rapid advancement in high performance computing, a number of recent
%work aims to design efficient mesh data structure that leverages modern computer
%hardware such as GPU. Linear Algebra Representation \cite{Dicarlo2014} proposes
%to use sparse matrix to encode adjacency information between $k$ and
%$(k-1)$-cells.  In this setting, local adjacency queries reduce to sparse matrix
%manipulations, which have been well studied by the high performance computing
%community.  Similarly, Mesh Matrix representation \cite{Zayer2017} directly uses
%a sparse matrix to store face-vertex adjacency information while tracking the
%vertex ordering.  Common mesh operations such vertex normal computation are
%cast as linear algebra operations enabled by their customized action maps.
%More recently, \cite{Mahmoud2021} combines the mesh-as-sparse-matrix design with 
%surface partitioning to form Ribbon-matriX Mesh (aka RXMesh) that captures
%geometric locality with modern GPU's memory.
%\QZ{Maybe add some drawbacks of these approaches.}
%
%% Other mesh data structure.
%All of the aforementioned data structures store topological information about a
%mesh, the corresponding geometric information is often stored separately as an
%array of vertex coordinates. In contrast, Signpost data structure
%\cite{Sharp2019} proposes to store the direction and distance to adjacent
%vertices from a given vertex, which is sufficient to encode intrinsic
%triangulation of 2-manifold. Both vertex coordinates and SignPost data can be
%captured as per-element attributes in our IDSA data structure.

%\DP{https://dl.acm.org/doi/abs/10.1145/1071866.1071882}

%\url{https://www.ece.ucdavis.edu/~ahdhn/files/RXMesh_SIGGRAPH2021.pdf}
%\ZJ{Don't forget the original tuple 1999 paper.}

%OpenVolumeMesh, IntrisicTriangulation, 

%\QZ{
%Classic mesh data structure:
%
%\begin{itemize}
%\item \cite{Requicha1980}: Early solid representations.
%\item \cite{Maentylae1987}: Book containing half-edge data structure.
%\item \cite{Baumgart1972}: Winged edge.
%\item \cite{Guibas1985}: Quad edge.
%\item \cite{Brisson1989}: Cell-tuple.
%\item \cite{kremer2013openvolumemesh}: OpenVolumeMesh.  Extends half edge to half face.  Store
%top-down and optionally bottom-up incidence relations.  Handles non-manifold 2d
%and 3d cell complexes.  Only handle up to 3 dimensional cell complex.
%\item \cite{Dyedov2015}: Array-based half-facet data structure. Use structure of
%arrays for storage.  Only store $d$, $d-1$ and 1-dimensional entities (i.e.
%edges are not explicitly stored).  Works with non-manifold and mixed dimensional
%mesh.
%\end{itemize}
%
%Mesh as sparse matrix representations:
%
%\begin{itemize}
%\item \cite{Dicarlo2014}: LAR: Linear Algebra Representation.
%\item \cite{Zayer2017}: Mesh Matrix.
%\item \cite{Mahmoud2021}: RXMesh.
%\end{itemize}
%
%Other data structures:
%\begin{itemize}
%\item \cite{Sharp2019}: Signpost data structure for intrinsic Delaunay.
%\end{itemize}
%}

\subsection{Domain specific languages in graphics}
%Other PL: halide (published in POPL) assembles for regular structure, Simit for fixed unstructured mesh.
%Taichi [Hu 2020] sparse volume data.
%Penrose [Ye 2020] \ZJ{good writing example}.
%Taco
Our abstraction model of mesh processing algorithms draw inspiration from domain
specific languages (DSL) in graphics.  For dense regularly structured data such
as images, Halide \cite{ragan2013halide} popularized the idea of decoupling image
processing operations from low level scheduling tasks. Similar abstraction that
separates algorithm description from low level data structure and/or parallel
architecture can also be found in other DSLs such as Simit
\cite{kjolstad2016simit} for simulation over triangle meshes, Taco
\cite{kjolstad2017taco} for dense and sparse tensor algebra, Taichi
\cite{hu2019taichi} for simulation over sparse volumetric data, and Penrose
\cite{ye2020penrose} for generating diagrams from math notation.

\subsection{Parallel Meshing}
%\cite{zhou2012tools} and others from M. Shephard group: mostly on how to partition the mesh, and communicate between processors.
%
%\ZJ{Also, a lot work on partition the mesh. MPI (distributed memory) vs TBB with shared memory, we are claiming speed-up and ease-of-use only.} 
%
%\DP{Review the works, and the ones cited by \url{https://scholar.google.com/citations?user=i0zT6P4AAAAJ&hl=en} }

% \DP{This is for Gurki and Teseo}

To meet the demand of generating large meshes,
a number of popular mesh generation algorithms have been redesigned to
leverage modern parallel computing hardware, both in a shared memory and distributed memory setting. Typically a divide-and-conquer strategy is adopted where a mesh is partitioned to run local processing operations
on each subdomain in parallel.  There are two key challenges involved: (1) how to
handle operations involving elements shared by multiple partitions; (2) how to
ensure load stay balanced across different processors as the mesh evolves.

One way to mitigate both challenges is to ensure mesh is partitioned into
similar sized patches with high area to boundary ratio.
A large number of partitioning strategies are available, including
clustering-based approaches \cite{Mahmoud2021}, spacial-hierarchy-based approach
\cite{loseille2017unique,lo2012parallel}, space-filling-curve-based approach
\cite{marot2019one,borrell2018parallel}, and general purpose graph partitioning \cite{karypis1998fast}. Many variations of space-filling curves have also been used to construct mesh partitions \cite{chrisochoides2006parallel, aluru1997parallel}.
%
To handle potential conflicts that may arise at partition boundaries,
various synchronization strategies have been proposed
\cite{okusanya1996parallel,chrisochoides2003parallel,chrisochoides2006parallel} to minimize the amount of
communication.
%

After generating the submeshes, some methods allow each compute node to work on them independently without synchronization. Once all threads are done, the meshes are merged \cite{https://doi.org/10.1111/1467-8659.1230129, chen2010merge, funke2017parallel, blelloch1999design}. However these methods require complicated merge steps since the tetrahedra in the intermediate boundaries may not align. There are some techniques that compromise the Delaunay condition in some cases, so that the merging operation can be simpler \cite{lachat2014parallel}. 
%
To avoid the tricky merge operations, other parallel strategies maintain a single complete Delaunay tetrahedralization and use synchronization techniques to avoid race conditions when working on a partition boundary \cite{okusanya19973, chrisochoides2003parallel}. The parallel constrained Delaunay meshing algorithm \cite{chew1997parallel} cleverly defines the boundary and edge constrains to reduce the variable and unpredictable communication patterns. Some other techniques use locks for handling conflicts and data races \cite{blandford2006engineering, batista2010parallel, foteinos2011dynamic}. 
%

Another set of methods use recursive divide-and-conquer techniques for parallel implementation on shared memory machines \cite{marot2020quality}. All threads independently work on the internal parts of the mesh and skip the operations at the boundary. After this phase, processing of only the boundary elements becomes the new problem. This technique is then recursively used until all the mesh elements are processed. A similar set of techniques use clever space-filling curves for re-partitioning the mesh boundaries after each recursive phase \cite{chrisochoides2006parallel, aluru1997parallel}. %Using any of these approaches in distributed scenarios will be highly inefficient as they require numerous mesh repartitionings, which will have a large communication overhead.
%

Since the submesh boundaries are the main areas of concern, some methods entirely avoid any operations on these boundaries while ensuring the correctness of the result \cite{galtier1996prepartitioning, linardakis2006delaunay}. These methods precompute the domain separators such that their facets are Delaunay admissible. This  completely eliminates synchronization overheads, but only applies for Delaunay meshing.
%

Another conflict handling strategy is to simply reject the offending operations
and try executing them later with a new domain partitioning \cite{marot2019one}.
This reject-and-repartition strategy may not guarantee algorithm termination,
thus special care is needed to handle this case.
%

As the domain mesh evolves, keeping load balanced across processors becomes
critical. Typically, this is done by periodically repartitioning the updated mesh.
\citet{zhou2012tools} proposes a predictive load balancing method to keep
partitions balanced. \citet{marot2019one} uses simple rescaling of the
space-filling curve to repartition the domain.

In this work, we are targeting only shared-memory parallelism, thus making the problem of reducing communications between processors less relevant. We use a graph-based space partitioning technique \cite{karypis1998fast} due to its simplicity and availability as open-source code (METIS), but we use it only to reduce the risk of conflicts. To avoid conflicts, we use a shared memory locking mechanism. This approach is only possible for shared-memory parallelism but has the major advantage of not requiring rebalancing and to respect, to a certain degree, the execution order prescribed by the user-code. This approach is possible thanks to the availability of efficient parallel atomic instructions, and parallel libraries based on them (oneTBB).


%\textbf{Gurki first draft:}

%Parallel delaunay triangulation is a well studied problem and while the exact strategies may not work, it is very relevant for parallel FtetWild. FtetWild begins with Delaunay tetrahedralization which is followed by some custom mesh optimization operations which affect the mesh at a small neighbourhood in each iteration. Delaunay techniques which use point insertion on an initial mesh follow similar properties and various strategies have been developed to parallelize the operation \cite{chrisochoides2006parallel}.

%A triangulated mesh can be partitioned into multiple submeshes for use in both distributed and shared memory scenarios. Some generic graph/mesh partitioning libraries like METIS \cite{karypis1998fast} can be used for this purpose. Many variations of space-filling curves have also been used to construct mesh partitions \cite{chrisochoides2006parallel, aluru1997parallel} for use in parallel delaunay algorithms. METIS was used in this project since it is easy to use and can be extended to distributed memory versions.

% After generating the submeshes, some collection of methods allow each compute node to work on them independently without any synchronization. Once all threads are done, all delaunay meshes are merged into a single larger mesh \cite{https://doi.org/10.1111/1467-8659.1230129, chen2010merge, funke2017parallel, blelloch1999design}. Each partition can be stored on a node of a distributed cluster, if the algorithm needs to be extended for distributed scenarios. However these methods require complicated merge steps since the tets in the intermediate boundaries may not align. It is especially difficult to use this approach for FtetWild since the mesh optimization operations may lead to wildly different intermediate boundaries (both in tets and vertices). There are some techniques that compromise the Delaunay condition in some cases, so that the merging operation can be simpler \cite{lachat2014parallel}. But this category of methods are not relevant for FtetWild.

% To avoid the tricky merge operations, other parallel strategies maintain a single complete Delaunay tetrahedralization and use synchronization techniques to avoid race conditions when working on a partition boundary \cite{okusanya19973, chrisochoides2003parallel}. Parallel Constrained Delaunay Meshing algorithm \cite{chew1997parallel} cleverly defines the boundary and edge constrains to reduce the variable and unpredictable communication patterns. Some other techniques use locks for handling conflicts and data races \cite{blandford2006engineering, batista2010parallel, foteinos2011dynamic}. Since these approaches are very specific to Delaunay, none of these can be directly used in FtetWild. But since this category of methods are easier to extend to distributed memory scenarios, the lock based approach is used in this paper.

% Another set of methods use recursive divide-and-conquer techniques for parallel implementation on shared memory machines \cite{marot2020quality}. All threads independently work on the internal parts of the mesh and skip the operations at the boundary. After this phase, processing of only the boundary elements becomes the new problem. This technique is then recursively used until all the mesh elements are processed. A similar set of techniques use clever space-filling curves for re-partitioning the mesh boundaries after each recursive phase \cite{chrisochoides2006parallel, aluru1997parallel}. Using any of these approaches in distributed scenarios will be highly inefficient as they require numerous mesh repartitionings , which will have a huge communication overhead.

% Since the submesh boundaries are the main areas of concern, some methods entirely avoid any operations on these boundaries while ensuring the correctness of the result \cite{galtier1996prepartitioning, linardakis2006delaunay}. These Decoupled methods precompute the domain separators such that their facets are Delaunay admissible. This leads to 100\% code reuse and completely eliminates synchronization overheads. They are however difficult to extend for 3D meshes and can't directly be extended for the different kinds of operations in FtetWild.

\subsection{Scope of Mesh Editing}

\paragraph{Mesh Generation}

Tetrahedral meshing algorithms heavily rely on mesh editing operations. The most common approaches are Delaunay methods \cite{Shewchuk:1998:TMG,Ruppert:1995:ADR,Remacle:2017:ATL,Du:2003:TMG,Alliez:2005:VTM,Tournois:2009:IDR,MURPHY:2001:APP,CohenSteiner:2002:CDT,Chew:1987:CDT,Si:2005:MPL,Shewchuk:2002:CDT,Si:2014:ICA,Cheng:2008:APD,Boissonnat:2005:PGS,Jamin:2015:CAG,Dey:2008:DAD,Chen:2004:ODT,SHEWCHUK-triangle1,Cheng:2012:DMG,Bishop2016,Busaryev:RMI:2009,triangulation_in_cgal,Si:2015}, which strive to generate meshes satisfying the Delaunay condition, grid methods \cite{Yerry1983,BERN1994,Molino:2003:TMG,Bronson:2013:LCC,Labelle:2007:ISF,Doran:2013:ISI,code:quartet}, which start from a regular lattice or with a hierarchical space partitioning and optionally intersect the background mesh with the input surface, and front-advancing methods \cite{Sadek1980,Cuilliere:2013:ADM,Alauzet:2014:ACA,Haimes:2014:MMO}, which insert one element at a time, growing the volumetric mesh (i.e. marching in space), until the entire volume is filled .

These algorithms rely on local operations on mesh data-structures, and benefit from our framework to simplify the implementation and gain automatic parallelization. We discuss an implementation of one the more recent algorithms \cite{hu2018tetrahedral,Hu:2019:fTetWild} in Section \ref{wmtk:sec:applications}. Note that some of these algorithms use local operation that are not implemented yet (such as 5-6 swap), but they could be added to our framework.

\paragraph{Constrained Meshing.}

Downstream applications often require meshes to satisfy either quality (avoidance of zero volume elements) or geometric (distance to the input surface) constraints. For example, \citet{Mandad:2015} creates a surface approximation within a tolerance volume, the TetWild algorithms \cite{hu2018tetrahedral,Hu:2019:fTetWild} use an envelope \cite{Wang:2021} to restricts the geometry of the boundary of the tetrahedral mesh, \cite{Brochu:2012} adds constraints to local remeshing to avoid interpenetrations in simulations, and \cite{gumhold2003intersection} extends mesh simplification \cite{Garland:1999,Popovic:1997} to ensure a non self-intersecting result. 

These criteria are explicitly modeled as invariants in our framework, and they can be easily swapped in and out existing implementations, as we demonstrate in Section \ref{wmtk:sec:applications}.

\paragraph{Mesh Improvement.} 

Mesh improvements modifies an existing mesh by changing its connectivity and position of the vertices to improve the quality of its elements \cite{Canann1996,CANANN1993185,Lori1998,Lipman:2012:BDM,Chen:2004:ODT,Alliez:2005,Feng:2018:COD,hu2018tetrahedral,Alexa:2019,Klingner07aggressive}.
%
%
We show in Section \ref{wmtk:sec:applications} a reimplementation of \cite{Alexa:2019} in IDAS form.

\paragraph{Dynamic Remeshing and Adaptive Mesh Refinement (AMR)} 

Simulations involving large deformations are common in computer graphics, and if the surface or volume deformed is represented by a mesh, it is inevitable that after a large deformation the quality of the elements will deteriorate, and the mesh will have to be updated. Additionally, it is often required to concentrate more elements in regions of interest whose location is changing during the simulation, for example to capture a fold in a cloth simulation, or a fracture in a brittle material.
%
These two challenges are tackled in elastoplastic and viscoplastic simulations \cite{Hutchinson:1996,Bargteil:2007,Wicke:2010,Wojtan:2008}, in fluid simulations \cite{Misztal:2012,Klingner:2006,Ando:2013,Chentanez:2007,clausen:2013}, in cloth simulation \cite{Villard:2002,Bender:2013,Li:2005,Narain:2012,Narain:2013,Pfaff:2014,Simnett:2009}, and fracture simulation \cite{Busaryev:2013}. All these algorithms could benefit from our contribution, to simplify their implementation and obtaining speedup due to the automatic parallelization offered by our approach.

A different approach is discussed in \cite{Grinspun:2002}, where the refinement is performed on the basis to avoid the difficulties with explicit remeshing. However, this approach cannot coarsen a dense input, and also cannot increase the quality of elements, making it usable only for specific scenarios \cite{Grinspun:2002}. Our approach aims at lowering the barrier for integrating explicit remeshing algorithms in simulation applications, thus allowing to directly use standard simulation methods on adaptive meshes without having to pay the high implementation cost for the mesh generation.

When remeshing is paired with algorithms simulating contacts that do not tolerate interpenetrations (for example \cite{Li2020IPC}), it is necessary to ensure that adaptive remeshing does not break this invariant. This can be achieved adding non-penetration constraints to each local mesh editing operations, as proposed in \cite{Brochu:2012}. Our framework is ideal for developing such methods, as additional constraints can be added to existing mesh editing algorithms with minimal modifications, as we demonstrate in Section \ref{wmtk:sec:applications}.


% \paragraph{Adaptive Rendering} Nanite, LOD, terrain modeling and representation, other approaches, \DP{Jeremie or Yixin?}
% \TODO{Daniele}
% some random citations to start from

% C-BDAM - Compressed Batched Dynamic Adaptive Meshes for Terrain Rendering   eg2006-cbdam.pdf
% Enrico Gobbetti, Fabio Marton, Paolo Cignoni, Marco Di Benedetto, Fabio Ganovelli
% Computer Graphics Forum, Volume 25, Number 3 - sep 2006

% Adaptive TetraPuzzles: Efficient Out-of-Core Construction and Visualization of Gigantic Multiresolution Polygonal Models   vbdam\_sig04.pdf
% Paolo Cignoni, Fabio Ganovelli, Enrico Gobbetti, Fabio Marton, Federico Ponchio, Roberto Scopigno
% ACM Trans. on Graphics, Volume 23, Number 3, page 796-803 - 2004

% Planet-sized batched dynamic adaptive meshes (P-BDAM)  
% Paolo Cignoni, Fabio Ganovelli, Enrico Gobbetti, Fabio Marton, Federico Ponchio, Roberto Scopigno
% Proc. of IEEE Visualization 2003, page 147-155 - 2003

% Selective Refinement Queries for Volume Visualization of Unstructured Tetrahedral Meshes  
% Paolo Cignoni, Paola Magillo, Leila De Floriani, Enrico Puppo, Roberto Scopigno
% IEEE Transaction on Visualization and Computer Graphics, Volume 10, Number 1, page 29-45 - Feb 2004


\paragraph{Parametrization} 

Conformal mesh parametrization algorithms adapt the mesh during optimization, as a a fixed triangulation restricts the space of metrics realizable \cite{luo2004combinatorial,Campen:2017:SimilarityMaps,Campen:2017:OnSimilarityMaps,campen2018seamless,gu2018discrete,gu2018discrete2,springborn2019ideal,sun2015discrete}. Two very recent works \cite{Gillespie:2021:DCE,Campen:2021} introduce robust algorithms based on Ptolemy flips to compute conformal maps satisfying a prescribed metric.

All these methods require changing the mesh connectivity of a triangle mesh, and could thus benefit from our framework to simplify their implementation and parallelize the mesh editing operations. 

\paragraph{Mesh Arrangements/Boolean Operations} 

Boolean operations are basic algorithms often used in geometry processing applications. Recently, \cite{zhou2016mesh} proposed a robust way to compute them by constructing a space arrangement, and then filtering the result using the generalized winding number \cite{Jacobson:2013}. A similar approach, using an approximated meshing algorithm, has been extended in \cite{Hu:2019:fTetWild}, using a tetrahedral mesher to create the initial arrangement. The reimplementation of TetWild introduced in this paper (Section \ref{wmtk:sec:applications}) can be extended for a similar purpose.
